{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90defdd6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#   1. INSTALL & IMPORT\n",
    "# ============================================================\n",
    "!pip install -q sentence-transformers scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "#   2. LOAD DATASET\n",
    "# ============================================================\n",
    "filename = \"daftar_objek_50.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Tambah kolom untuk menyimpan clue history (untuk training NB)\n",
    "if \"clue_history\" not in df.columns:\n",
    "    df[\"clue_history\"] = df[\"deskripsi\"].copy()\n",
    "\n",
    "print(f\"âœ… Dataset loaded: {len(df)} objek\")\n",
    "\n",
    "# ============================================================\n",
    "#   3. LOAD MODELS\n",
    "# ============================================================\n",
    "# Sentence Transformer (Semantic)\n",
    "st_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# TF-IDF + Naive Bayes (NLP)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "nb_model = MultinomialNB(alpha=0.1)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# ============================================================\n",
    "#   4. BUILD EMBEDDINGS & TRAIN NLP\n",
    "# ============================================================\n",
    "def gabung_teks(row):\n",
    "    return f\"{row['objek']} - {row['deskripsi']}\"\n",
    "\n",
    "def rebuild_all_models():\n",
    "    global objek_list, objek_only, objek_embeddings\n",
    "    global X_tfidf, y_encoded\n",
    "\n",
    "    # === Sentence Transformer ===\n",
    "    objek_list = df.apply(gabung_teks, axis=1).tolist()\n",
    "    objek_only = df[\"objek\"].tolist()\n",
    "    objek_embeddings = st_model.encode(objek_list, convert_to_tensor=True)\n",
    "\n",
    "    # === Naive Bayes ===\n",
    "    # Buat training data dari clue_history\n",
    "    train_texts = []\n",
    "    train_labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        clues = row[\"clue_history\"].split(\", \")\n",
    "        for c in clues:\n",
    "            if len(c.strip()) > 2:\n",
    "                train_texts.append(c.strip().lower())\n",
    "                train_labels.append(row[\"objek\"])\n",
    "\n",
    "    if len(train_texts) > 0:\n",
    "        X_tfidf = tfidf.fit_transform(train_texts)\n",
    "        y_encoded = label_encoder.fit_transform(train_labels)\n",
    "        nb_model.fit(X_tfidf, y_encoded)\n",
    "\n",
    "    print(\"âœ… Sentence Transformer + Naive Bayes siap!\")\n",
    "\n",
    "rebuild_all_models()\n",
    "\n",
    "# ============================================================\n",
    "#   5. FUNGSI PREDIKSI HYBRID\n",
    "# ============================================================\n",
    "def predict_semantic(clue, top_k=10):\n",
    "    \"\"\"Prediksi pakai Sentence Transformer\"\"\"\n",
    "    clue_emb = st_model.encode(clue, convert_to_tensor=True)\n",
    "    scores = util.pytorch_cos_sim(clue_emb, objek_embeddings)[0]\n",
    "\n",
    "    hasil = {}\n",
    "    for i, score in enumerate(scores):\n",
    "        hasil[objek_only[i]] = float(score)\n",
    "    return hasil\n",
    "\n",
    "def predict_naive_bayes(clue):\n",
    "    \"\"\"Prediksi pakai Naive Bayes\"\"\"\n",
    "    try:\n",
    "        X_new = tfidf.transform([clue.lower()])\n",
    "        proba = nb_model.predict_proba(X_new)[0]\n",
    "        classes = label_encoder.classes_\n",
    "\n",
    "        hasil = {}\n",
    "        for i, p in enumerate(proba):\n",
    "            hasil[classes[i]] = float(p)\n",
    "        return hasil\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def predict_hybrid(clue, top_k=5, weight_st=0.5, weight_nb=0.5):\n",
    "    \"\"\"Gabungan Semantic + Naive Bayes\"\"\"\n",
    "\n",
    "    # Dapat skor dari kedua model\n",
    "    scores_st = predict_semantic(clue)\n",
    "    scores_nb = predict_naive_bayes(clue)\n",
    "\n",
    "    # Normalisasi skor ST ke range 0-1\n",
    "    max_st = max(scores_st.values()) if scores_st else 1\n",
    "    min_st = min(scores_st.values()) if scores_st else 0\n",
    "    range_st = max_st - min_st if max_st != min_st else 1\n",
    "\n",
    "    # Kombinasi skor\n",
    "    final_scores = {}\n",
    "    for objek in objek_only:\n",
    "        st_norm = (scores_st.get(objek, 0) - min_st) / range_st\n",
    "        nb_score = scores_nb.get(objek, 0)\n",
    "\n",
    "        # Weighted average\n",
    "        final_scores[objek] = (weight_st * st_norm) + (weight_nb * nb_score)\n",
    "\n",
    "    # Sort dan ambil top_k\n",
    "    sorted_scores = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    hasil = []\n",
    "    for objek, score in sorted_scores[:top_k]:\n",
    "        hasil.append({\n",
    "            \"objek\": objek,\n",
    "            \"score\": round(score, 4),\n",
    "            \"st\": round(scores_st.get(objek, 0), 4),\n",
    "            \"nb\": round(scores_nb.get(objek, 0), 4)\n",
    "        })\n",
    "    return hasil\n",
    "\n",
    "# ============================================================\n",
    "#   6. FUNGSI BELAJAR DARI FEEDBACK\n",
    "# ============================================================\n",
    "def learn_from_feedback(clue, jawaban_benar, deskripsi_tambahan=None):\n",
    "    global df\n",
    "\n",
    "    idx = df[df[\"objek\"].str.lower() == jawaban_benar.lower()].index\n",
    "\n",
    "    if len(idx) > 0:\n",
    "        i = idx[0]\n",
    "        # Update deskripsi\n",
    "        old_desc = df.at[i, \"deskripsi\"]\n",
    "        tambahan = deskripsi_tambahan if deskripsi_tambahan else clue\n",
    "        df.at[i, \"deskripsi\"] = f\"{old_desc}, {tambahan}\"\n",
    "\n",
    "        # Update clue_history (untuk Naive Bayes) - repeat 3x untuk boost\n",
    "        old_clues = df.at[i, \"clue_history\"]\n",
    "        boost = f\"{clue}, {clue}, {clue}\"  # Triple boost!\n",
    "        df.at[i, \"clue_history\"] = f\"{old_clues}, {boost}\"\n",
    "\n",
    "        print(f\"ğŸ”„ '{jawaban_benar}' diperkuat dengan: {tambahan}\")\n",
    "    else:\n",
    "        desc = deskripsi_tambahan if deskripsi_tambahan else f\"{jawaban_benar} adalah {clue}\"\n",
    "        boost = f\"{clue}, {clue}, {clue}\"\n",
    "        baru = pd.DataFrame({\n",
    "            \"objek\": [jawaban_benar],\n",
    "            \"deskripsi\": [desc],\n",
    "            \"clue_history\": [f\"{desc}, {boost}\"]\n",
    "        })\n",
    "        df = pd.concat([df, baru], ignore_index=True)\n",
    "        print(f\"â• Objek baru: {jawaban_benar}\")\n",
    "\n",
    "    # Rebuild KEDUA model\n",
    "    rebuild_all_models()\n",
    "    print(\"âœ… Semantic + NLP model diperbarui!\")\n",
    "\n",
    "# ============================================================\n",
    "#   7. AUTO-SAVE\n",
    "# ============================================================\n",
    "feedback_counter = 0\n",
    "auto_save_every = 3\n",
    "save_filename = \"daftar_objek_updated.csv\"\n",
    "\n",
    "def save_dataset(filename=None):\n",
    "    global save_filename\n",
    "    if filename:\n",
    "        save_filename = filename\n",
    "    df.to_csv(save_filename, index=False)\n",
    "    print(f\"ğŸ’¾ Disimpan: {save_filename} ({len(df)} objek)\")\n",
    "\n",
    "def check_auto_save():\n",
    "    global feedback_counter\n",
    "    feedback_counter += 1\n",
    "    print(f\"ğŸ“Š Feedback: {feedback_counter}/{auto_save_every}\")\n",
    "    if feedback_counter >= auto_save_every:\n",
    "        save_dataset()\n",
    "        feedback_counter = 0\n",
    "\n",
    "# ============================================================\n",
    "#   8. GAME INTERAKTIF\n",
    "# ============================================================\n",
    "def play_game():\n",
    "    print(\"\\n\" + \"=\"*55)\n",
    "    print(\"ğŸ® GAME TEBAK OBJEK - ML + NLP EDITION\")\n",
    "    print(\"=\"*55)\n",
    "    print(\"Perintah: 'quit' keluar | 'save' simpan | 'stat' statistik\\n\")\n",
    "\n",
    "    stats = {\"benar\": 0, \"salah\": 0}\n",
    "\n",
    "    while True:\n",
    "        clue = input(\"ğŸ” Clue: \").strip()\n",
    "\n",
    "        if clue.lower() == \"quit\":\n",
    "            save_dataset()\n",
    "            akurasi = stats[\"benar\"]/(stats[\"benar\"]+stats[\"salah\"])*100 if (stats[\"benar\"]+stats[\"salah\"]) > 0 else 0\n",
    "            print(f\"\\nğŸ“ˆ Akurasi sesi ini: {akurasi:.1f}% ({stats['benar']}/{stats['benar']+stats['salah']})\")\n",
    "            print(\"ğŸ‘‹ Sampai jumpa!\")\n",
    "            break\n",
    "        elif clue.lower() == \"save\":\n",
    "            save_dataset()\n",
    "            continue\n",
    "        elif clue.lower() == \"stat\":\n",
    "            print(f\"ğŸ“Š Benar: {stats['benar']} | Salah: {stats['salah']}\")\n",
    "            continue\n",
    "        elif not clue:\n",
    "            continue\n",
    "\n",
    "        hasil = predict_hybrid(clue, top_k=5)\n",
    "\n",
    "        print(f\"\\nğŸ¤– Tebakan (ST=Semantic, NB=NaiveBayes):\")\n",
    "        for i, h in enumerate(hasil, 1):\n",
    "            print(f\"   {i}. {h['objek']:20} [Final: {h['score']:.3f} | ST: {h['st']:.3f} | NB: {h['nb']:.3f}]\")\n",
    "\n",
    "        tebakan = hasil[0][\"objek\"]\n",
    "        print(f\"\\nğŸ¯ Tebakan: {tebakan}\")\n",
    "\n",
    "        feedback = input(\"âœ… Benar? (y/n/skip): \").strip().lower()\n",
    "\n",
    "        if feedback == \"y\":\n",
    "            print(\"ğŸ‰ Benar!\")\n",
    "            stats[\"benar\"] += 1\n",
    "            learn_from_feedback(clue, tebakan)\n",
    "            check_auto_save()\n",
    "        elif feedback == \"n\":\n",
    "            stats[\"salah\"] += 1\n",
    "            jawaban = input(\"ğŸ“ Jawaban benar: \").strip()\n",
    "            if jawaban:\n",
    "                desc = input(\"ğŸ“– Deskripsi (enter skip): \").strip()\n",
    "                learn_from_feedback(clue, jawaban, desc if desc else None)\n",
    "                check_auto_save()\n",
    "        else:\n",
    "            print(\"â­ï¸ Skip\")\n",
    "\n",
    "        print(\"-\"*55 + \"\\n\")\n",
    "\n",
    "# ============================================================\n",
    "#   9. START\n",
    "# ============================================================\n",
    "print(\"\\nğŸš€ Ketik play_game() untuk mulai!\")\n",
    "print(\"ğŸ“Š Atau predict_hybrid('clue') untuk test\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
